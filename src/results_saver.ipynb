{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../data_iteration')\n",
    "\n",
    "import functools\n",
    "import itertools\n",
    "import copy\n",
    "import datetime\n",
    "import collections\n",
    "import logging\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import tempfile\n",
    "import h5py\n",
    "\n",
    "#from data_iterators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _HDF5_Model_base(ABC):\n",
    "    def __init__(self, *, model: str, root_directory='results'):\n",
    "        self.model = model\n",
    "        self.root_directory = root_directory\n",
    "        \n",
    "    @property\n",
    "    def _dispatcher_path(self):\n",
    "        return os.path.join(self.root_directory, self.model, 'dispatcher.csv')\n",
    "        \n",
    "    def _create_dispatcher(self):\n",
    "        with open(self._dispatcher_path, mode='w', newline='') as dis_file:\n",
    "            dis_writer = csv.writer(dis_file)\n",
    "            dis_writer.writerow(['dir_name', 'hyperparameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterInspector(_HDF5_Model_base):\n",
    "    def __getitem__(self, item):\n",
    "        assert isinstance(item, int)\n",
    "        with open(self._dispatcher_path, mode='r', newline='') as dis_file:\n",
    "            dis_reader = csv.reader(dis_file)\n",
    "            for (directory, hp) in itertools.islice(dis_reader, 1 + item, None):\n",
    "                return json.loads(hp)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        result = ''\n",
    "        with open(self._dispatcher_path, mode='r', newline='') as dis_file:\n",
    "            dis_reader = csv.reader(dis_file)\n",
    "            for i, (directory, hp) in enumerate(itertools.islice(dis_reader, 1, None)):\n",
    "                result += f'[{i}]: < {str(json.loads(hp))} >\\n'\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _HDF5_Hyperparameters_base(_HDF5_Model_base):\n",
    "    def __init__(self, *, model: str, hyperparameters: dict, root_directory = 'results'):\n",
    "        super().__init__(model = model, root_directory=root_directory)\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self._model_directory_cached = None\n",
    "            \n",
    "    def _create_model_directory(self):\n",
    "        d_path = self._dispatcher_path\n",
    "        serialization = json.dumps(self.hyperparameters)\n",
    "        directory_prefix =  datetime.datetime.now().strftime('%Y-%m-%d_%H:%M_')\n",
    "        directory = tempfile.mkdtemp( prefix=directory_prefix, dir=os.path.dirname(d_path) )\n",
    "        \n",
    "        with open(d_path, mode='a', newline='') as dis_file:\n",
    "            dis_writer = csv.writer(dis_file)\n",
    "            dis_writer.writerow([directory, serialization])\n",
    "        return directory\n",
    "        \n",
    "    def _compare_hyperparameters(self, loaded, searched):\n",
    "        return loaded == searched\n",
    "    \n",
    "    @property\n",
    "    def _model_directory(self): # == use dispatcher\n",
    "        if self._model_directory_cached is not None:\n",
    "            return self._model_directory_cached\n",
    "        \n",
    "        with open(self._dispatcher_path, newline='') as dis_file:\n",
    "            dis_reader = csv.reader(dis_file)\n",
    "            for (directory, hp) in itertools.islice(dis_reader, 1, None):\n",
    "                if self._compare_hyperparameters(json.loads(hp), self.hyperparameters):\n",
    "                    self._model_directory_cached = directory\n",
    "                    return self._model_directory_cached\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _HDF5_Concrete_base(_HDF5_Hyperparameters_base):\n",
    "    def __init__(self, *\n",
    "        , model: str , hyperparameters: dict , root_directory = 'resluts'\n",
    "        , function_id: int\n",
    "        , dimension: int\n",
    "        , run: int\n",
    "        ):\n",
    "        super().__init__(model=model, hyperparameters=hyperparameters, root_directory=root_directory)\n",
    "        \n",
    "        self.run = run\n",
    "        self.dimension = dimension\n",
    "        self.function_id = function_id\n",
    "        self.init()\n",
    "    \n",
    "    @property\n",
    "    def hdf5_final_path(self):\n",
    "        return os.path.join(self._model_directory, str(self.function_id),\n",
    "            str(self.dimension), f'{self.run}.hdf5')\n",
    "    @property\n",
    "    def hdf5_tmp_path(self):\n",
    "        return os.path.join(self._model_directory, str(self.function_id),\n",
    "            str(self.dimension), f'{self.run}.hdf5_tmp')\n",
    "    @abstractmethod\n",
    "    def init(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initilaizer(_HDF5_Concrete_base):\n",
    "    def init(self):\n",
    "        os.makedirs(os.path.dirname(self._dispatcher_path), exist_ok=True)\n",
    "        \n",
    "        if not os.path.exists(self._dispatcher_path):\n",
    "            self._create_dispatcher()\n",
    "            \n",
    "        model_directory = self._model_directory\n",
    "        if model_directory is None:\n",
    "            model_directory = self._create_model_directory()\n",
    "        \n",
    "        self._construct_hdf5_dataset(self.hdf5_tmp_path)\n",
    "    \n",
    "    def _construct_hdf5_dataset(self, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        # use only 'w'\n",
    "        with h5py.File(path, 'w') as h5f:\n",
    "            dset = h5f.create_dataset('prediction'\n",
    "                        , shape=(0,0)\n",
    "                        , chunks=(128,32)\n",
    "                        , maxshape=(None, None)\n",
    "                        , dtype=np.float32\n",
    "                        , fillvalue=-np.inf)\n",
    "            dset = h5f.create_dataset('target'\n",
    "                        , shape=(0,0)\n",
    "                        , chunks=(128,32)\n",
    "                        , maxshape=(None, None)\n",
    "                        , dtype=np.float32\n",
    "                        , fillvalue=-np.inf)\n",
    "            dset = h5f.create_dataset('training_samples'\n",
    "                        , shape=(0,)\n",
    "                        , chunks=(128,)\n",
    "                        , maxshape=(None,)\n",
    "                        , dtype=np.int32\n",
    "                        , fillvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saver(_HDF5_Concrete_base):\n",
    "    def init(self, disable=False):\n",
    "        self.completed = False\n",
    "        self._skip = 0\n",
    "        self.disable = disable\n",
    "        \n",
    "        if os.path.exists(self.hdf5_final_path):\n",
    "            logging.info(f'Skipping: Found already created final file: \"{self.hdf5_final_path}\"')\n",
    "            self.completed = True\n",
    "        else: # continue\n",
    "            self._skip = self._check_hdf5_dataset_state(self.hdf5_tmp_path)\n",
    "            self._already_computed = self._skip\n",
    "        \n",
    "    def finalize(self):\n",
    "        os.rename(self.hdf5_tmp_path, self.hdf5_final_path)\n",
    "        self.completed = True\n",
    "        \n",
    "    def _check_hdf5_dataset_state(self, path):\n",
    "        with h5py.File(path, 'r') as h5f:\n",
    "            prediction = h5f['prediction']\n",
    "            target = h5f['target']\n",
    "            training_size = h5f['training_samples']\n",
    "            \n",
    "            if prediction.shape != target.shape or prediction.shape[0] != training_size.shape[0]:\n",
    "                logging.warning(f'Shape mismatch prediction:{prediction.shape} target:{target.shape} training_samples:{training_size.shape} in file {path}')\n",
    "            \n",
    "            return min(min(prediction.shape[0], target.shape[0]), training_size.shape[0])\n",
    "            \n",
    "    def write_results_to_dataset(self, *, prediction, target, training_samples):\n",
    "        assert isinstance(prediction, np.ndarray)\n",
    "        assert isinstance(target, np.ndarray)\n",
    "        assert len(prediction.shape) == 1\n",
    "        assert target.shape == prediction.shape\n",
    "        training_samples = int(training_samples)\n",
    "        \n",
    "        if self.disable:\n",
    "            return \n",
    "        \n",
    "        with h5py.File(self.hdf5_tmp_path, 'a') as h5f:\n",
    "            pred_d = h5f['prediction']\n",
    "            targ_d = h5f['target']\n",
    "            size_d = h5f['training_samples']\n",
    "            \n",
    "            pred_d.resize( (self._skip+1, max(pred_d.shape[1], len(prediction))) )\n",
    "            pred_d[-1, :len(prediction)] = prediction\n",
    "            \n",
    "            targ_d.resize( (self._skip+1, max(targ_d.shape[1], len(prediction))) )\n",
    "            targ_d[-1, :len(target)] = target \n",
    "            \n",
    "            size_d.resize( (self._skip+1,) )\n",
    "            size_d[-1] = training_samples\n",
    "            \n",
    "            self._skip += 1\n",
    "            \n",
    "    @property\n",
    "    def already_computed(self):\n",
    "        return self._already_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(_HDF5_Concrete_base):\n",
    "    def init(self):\n",
    "        self.completed = False\n",
    "        \n",
    "        if os.path.exists(self.hdf5_final_path):\n",
    "            self.completed = True\n",
    "            self._data_path = self.hdf5_final_path\n",
    "        else:\n",
    "            logging.warning('Final result not found: using tmp')\n",
    "            self._data_path = self.hdf5_tmp_path\n",
    "            \n",
    "    @property\n",
    "    def data(self):\n",
    "        with h5py.File(self._data_path, 'r') as h5f:\n",
    "            prediction = h5f['prediction']\n",
    "            target = h5f['target']\n",
    "            size = h5f['training_samples']\n",
    "            return np.array(prediction), np.array(target), np.array(size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoaderIterator(_HDF5_Hyperparameters_base):\n",
    "    def __iter__(self):\n",
    "        m = copy.deepcopy(self)\n",
    "        m.files = []\n",
    "        for root, _, files in os.walk(self._model_directory):\n",
    "            for fil in files:\n",
    "                m.files.append(os.path.normpath(os.path.join(root, fil)))\n",
    "        m.type_output = collections.namedtuple(\n",
    "            'RunDescription', \n",
    "            ['function_id', 'dimension', 'run']\n",
    "        )\n",
    "        return m\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            filepath = self.files.pop() \n",
    "        except IndexError:\n",
    "            raise StopIteration()\n",
    "\n",
    "        func_id, dim, basefilename = filepath.split(os.sep)[-3:]\n",
    "        run = basefilename.split('.')[0]\n",
    "\n",
    "        conf = self.type_output(int(func_id), int(dim), int(run))\n",
    "        l = Loader(\n",
    "                model=self.model, \n",
    "                hyperparameters=self.hyperparameters, \n",
    "                function_id=conf.function_id,\n",
    "                dimension=conf.dimension,\n",
    "                run=conf.run,\n",
    "                root_directory=self.root_directory\n",
    "            )\n",
    "        return l, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import unittest\n",
    "    import shutil\n",
    "    import random\n",
    "    import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    class TestInitializer(unittest.TestCase):\n",
    "        testFileDirName = 's1412_test'\n",
    "        \n",
    "        @classmethod\n",
    "        def setUpClass(cls):\n",
    "            shutil.rmtree(cls.testFileDirName, ignore_errors=True)\n",
    "            \n",
    "        @classmethod\n",
    "        def tearDownClass(cls):\n",
    "            shutil.rmtree(cls.testFileDirName)\n",
    "            \n",
    "        def setUp(self):\n",
    "            #self.testFileDirName = self.__class__.testFileDirName\n",
    "            pass\n",
    "            \n",
    "        def test_loader(self):\n",
    "            # CREATE FIRST MODEL\n",
    "            Initilaizer( model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                    , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName\n",
    "                  )\n",
    "            self.assertTrue(os.path.exists(\n",
    "                os.path.join(self.testFileDirName, 'testModel1', 'dispatcher.csv') ))\n",
    "            m1_dir = set(os.listdir(os.path.join(self.testFileDirName, 'testModel1')))\n",
    "            m1_dir.remove('dispatcher.csv')\n",
    "            m1_dir = m1_dir.pop()\n",
    "            \n",
    "            self.assertTrue(os.path.exists(\n",
    "                os.path.join(self.testFileDirName, 'testModel1', m1_dir, '3', '2', '0.hdf5_tmp') ))\n",
    "            with open(os.path.join(self.testFileDirName, 'testModel1', 'dispatcher.csv'), 'r') as f:\n",
    "                self.assertEqual(sum(1 for line in f), 2)\n",
    "            self.assertEqual(len(os.listdir(self.testFileDirName)), 1)\n",
    "            \n",
    "            # CREATE SECOND MODEL\n",
    "            Initilaizer( model='testModel2', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                    , function_id=2 , dimension=4 , run=2 , root_directory = self.testFileDirName\n",
    "                  )\n",
    "            self.assertTrue(os.path.exists(\n",
    "                os.path.join(self.testFileDirName, 'testModel2', 'dispatcher.csv') ))\n",
    "            m2_dir = set(os.listdir(os.path.join(self.testFileDirName, 'testModel2')))\n",
    "            m2_dir.remove('dispatcher.csv')\n",
    "            m2_dir = m2_dir.pop()\n",
    "            self.assertTrue(os.path.exists(\n",
    "                os.path.join(self.testFileDirName, 'testModel2', m2_dir, '2', '4', '2.hdf5_tmp') ))\n",
    "            with open(os.path.join(self.testFileDirName, 'testModel2', 'dispatcher.csv'), 'r') as f:\n",
    "                self.assertEqual(sum(1 for line in f), 2)\n",
    "            self.assertEqual(len(os.listdir(self.testFileDirName)), 2)\n",
    "                \n",
    "                \n",
    "            # CREATE THIRD...\n",
    "            Initilaizer( model='testModel1', hyperparameters={'a': 12.3, 'b': 16} # <--- minor change of hyp.\n",
    "                    , function_id=1 , dimension=2 , run=0 , root_directory = self.testFileDirName\n",
    "                  )\n",
    "            self.assertTrue(os.path.exists(\n",
    "                os.path.join(self.testFileDirName, 'testModel1', 'dispatcher.csv') ))\n",
    "            with open(os.path.join(self.testFileDirName, 'testModel1', 'dispatcher.csv'), 'r') as f:\n",
    "                self.assertEqual(sum(1 for line in f), 3)\n",
    "            m3_dir = set(os.listdir(os.path.join(self.testFileDirName, 'testModel1')))\n",
    "            m3_dir.remove('dispatcher.csv')\n",
    "            m3_dir.remove(m1_dir)\n",
    "            m3_dir = m3_dir.pop()\n",
    "            \n",
    "            self.assertTrue(os.path.exists(\n",
    "                os.path.join(self.testFileDirName, 'testModel1', m3_dir, '1', '2', '0.hdf5_tmp') ))\n",
    "            self.assertEqual(len(os.listdir(self.testFileDirName)), 2)\n",
    "            \n",
    "            f = list(itertools.chain.from_iterable((files for subdir, dirs, files in os.walk(self.testFileDirName))))\n",
    "            self.assertEqual(len([files for files in f if '.hdf5' in files]), 3)\n",
    "            self.assertEqual( len([files for files in f if files == 'dispatcher.csv']), 2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    class TestSaverLoader(unittest.TestCase):\n",
    "        testFileDirName = 's1412_test'\n",
    "        \n",
    "        @classmethod\n",
    "        def setUpClass(cls):\n",
    "            shutil.rmtree(cls.testFileDirName, ignore_errors=True)\n",
    "            \n",
    "        @classmethod\n",
    "        def tearDownClass(cls):\n",
    "            shutil.rmtree(cls.testFileDirName)\n",
    "            \n",
    "        def setUp(self):\n",
    "            pass\n",
    "            \n",
    "        def test_loader(self):\n",
    "            # CREATE FIRST MODEL\n",
    "            Initilaizer(model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName\n",
    "                  )\n",
    "            \n",
    "            s = Saver(model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName\n",
    "                  )\n",
    "            \n",
    "            self.assertEqual(s.already_computed, 0)\n",
    "            \n",
    "            sizes = [10, 72, 111, 12, 312]\n",
    "            \n",
    "            for i,size in enumerate(sizes):\n",
    "                # saver\n",
    "                s.write_results_to_dataset(\n",
    "                    prediction = np.arange(size),\n",
    "                    target = np.arange(size) + 1,\n",
    "                    training_samples = size\n",
    "                )\n",
    "                \n",
    "                # loader\n",
    "                l = Loader(model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                    , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName\n",
    "                    )\n",
    "                \n",
    "                pred, tar, si = l.data\n",
    "                self.assertEqual(pred.shape[0], i+1)\n",
    "                self.assertEqual(tar.shape[0], i+1)\n",
    "                self.assertEqual(si.shape[0], i+1)\n",
    "                \n",
    "                for y in range(i+1):\n",
    "                    self.assertTrue(np.all(pred[y, :sizes[y]] == np.arange(sizes[y])))\n",
    "                    self.assertTrue(np.all(pred[y, sizes[y]:] == -np.inf))\n",
    "                    \n",
    "                    self.assertTrue(np.all(tar[y, :sizes[y]] == 1 + np.arange(sizes[y])))\n",
    "                    self.assertTrue(np.all(tar[y, sizes[y]:] == -np.inf))\n",
    "                    \n",
    "                    self.assertEqual(si[y], sizes[y])\n",
    "                    \n",
    "            ####  NEW SAVER\n",
    "            s = Saver(model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName )\n",
    "            self.assertEqual(len(sizes), s.already_computed)\n",
    "            \n",
    "            s.write_results_to_dataset(\n",
    "                prediction = np.arange(10),\n",
    "                target = np.arange(10) + 1,\n",
    "                training_samples = 10)\n",
    "            \n",
    "            l = Loader(model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName)\n",
    "            \n",
    "            pred, tar, si = l.data\n",
    "            self.assertEqual(pred.shape[0], len(sizes) + 1)\n",
    "            self.assertEqual(tar.shape[0], len(sizes) + 1)\n",
    "            self.assertEqual(si.shape[0], len(sizes) + 1)\n",
    "            \n",
    "            self.assertTrue(np.all(pred[-1, :10] == np.arange(10)))\n",
    "            self.assertTrue(np.all(pred[-1, 10:] == -np.inf))\n",
    "\n",
    "            self.assertTrue(np.all(tar[-1, :10] == 1 + np.arange(10)))\n",
    "            self.assertTrue(np.all(tar[-1, 10:] == -np.inf))\n",
    "\n",
    "            self.assertEqual(si[y], sizes[y])\n",
    "            \n",
    "            s.finalize()\n",
    "            \n",
    "            #### FINALIZE + LOADER AGAIN\n",
    "            \n",
    "            l = Loader(model='testModel1', hyperparameters={'a': 12.3, 'b': 15}\n",
    "                , function_id=3 , dimension=2 , run=0 , root_directory = self.testFileDirName)\n",
    "            \n",
    "            sizes = sizes + [10]\n",
    "            \n",
    "            for y in range(len(sizes)):\n",
    "                self.assertTrue(np.all(pred[y, :sizes[y]] == np.arange(sizes[y])))\n",
    "                self.assertTrue(np.all(pred[y, sizes[y]:] == -np.inf))\n",
    "\n",
    "                self.assertTrue(np.all(tar[y, :sizes[y]] == 1 + np.arange(sizes[y])))\n",
    "                self.assertTrue(np.all(tar[y, sizes[y]:] == -np.inf))\n",
    "\n",
    "                self.assertEqual(si[y], sizes[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    class TestIterator(unittest.TestCase):\n",
    "            testFileDirName = 's1412_test'\n",
    "\n",
    "            @classmethod\n",
    "            def setUpClass(cls):\n",
    "                shutil.rmtree(cls.testFileDirName, ignore_errors=True)\n",
    "\n",
    "            @classmethod\n",
    "            def tearDownClass(cls):\n",
    "                shutil.rmtree(cls.testFileDirName)\n",
    "\n",
    "            def setUp(self):\n",
    "                #self.testFileDirName = self.__class__.testFileDirName\n",
    "                pass\n",
    "\n",
    "            def create_data(self, model, hyperparameters, fid, dim, run, offset=0):\n",
    "                Initilaizer(model=model, hyperparameters=hyperparameters, \n",
    "                    function_id=fid , dimension=dim , run=run , root_directory = self.testFileDirName)\n",
    "\n",
    "                s = Saver(model=model, hyperparameters=hyperparameters, \n",
    "                        function_id=fid , dimension=dim , run=run , root_directory = self.testFileDirName )\n",
    "\n",
    "                for size in [2, 5, 3, 17, 13]:\n",
    "                    s.write_results_to_dataset(\n",
    "                        prediction = np.arange(size),\n",
    "                        target = np.arange(size) + fid + dim*100 + run*10000 + offset,\n",
    "                        training_samples = size)\n",
    "\n",
    "                s.finalize()\n",
    "\n",
    "\n",
    "            def check_data(self, data, fid, dim, run, offset = 0):\n",
    "                pred, targ, tras = data\n",
    "\n",
    "                for i, size in enumerate([2, 5, 3, 17, 13]):\n",
    "                    self.assertTrue(np.all(np.arange(size) == pred[i,:size]))\n",
    "                    self.assertTrue(np.all(-np.inf == pred[i,size:]))\n",
    "                    self.assertTrue(np.all(np.arange(size) + fid + dim*100 + run*10000 + offset == targ[i,:size]))\n",
    "                    self.assertTrue(np.all(-np.inf == targ[i,size:]))\n",
    "\n",
    "                    self.assertEqual(tras[i], size)\n",
    "\n",
    "\n",
    "            def test_loader(self):\n",
    "                c = collections.defaultdict(set)\n",
    "                for (model, of1) in [('testModel1', 10), ('testModel2', 11)]:\n",
    "                    for hyp in [{'hyp': 2}, {'hyp': 3}, {'hyp': 4}]:\n",
    "                        for fid in [11,22,33]:\n",
    "                            for dim in [10,20,30]:\n",
    "                                for run in [1,2,3]:\n",
    "                                    c[(model, hyp['hyp'])].add((fid,dim,run))\n",
    "                                    self.create_data(model, hyp, fid, dim, run, offset=of1 + hyp['hyp'])\n",
    "\n",
    "                for (model, of1) in [('testModel1', 10), ('testModel2', 11)]:\n",
    "                    for hyp in [{'hyp': 2}, {'hyp': 3}, {'hyp': 4}]:\n",
    "                        it = LoaderIterator(model=model, hyperparameters=hyp, \n",
    "                                            root_directory=self.testFileDirName )\n",
    "                        for (loader, ids) in it:\n",
    "                            c[(model, hyp['hyp'])].remove( (ids.function_id, ids.dimension, ids.run))\n",
    "                            self.check_data(loader.data, ids.function_id, ids.dimension, ids.run, offset=of1 + hyp['hyp'])\n",
    "                \n",
    "                for t in c.values():\n",
    "                    self.assertEqual(0, len(t))\n",
    "                    \n",
    "                hi = HyperparameterInspector(model='testModel1', root_directory=self.testFileDirName)\n",
    "                print(hi)\n",
    "                print(hi[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..WARNING:root:Final result not found: using tmp\n",
      "WARNING:root:Final result not found: using tmp\n",
      "WARNING:root:Final result not found: using tmp\n",
      "WARNING:root:Final result not found: using tmp\n",
      "WARNING:root:Final result not found: using tmp\n",
      "WARNING:root:Final result not found: using tmp\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: < {'hyp': 2} >\n",
      "[1]: < {'hyp': 3} >\n",
      "[2]: < {'hyp': 4} >\n",
      "\n",
      "{'hyp': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 1.653s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
