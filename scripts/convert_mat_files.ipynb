{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import collections\n",
    "\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "DATA_PATH = '../../exp_doubleEC_28_log_nonadapt/'\n",
    "DATA_OUTPUT = '../../npz-data/'\n",
    "\n",
    "if False:\n",
    "    shutil.rmtree(DATA_OUTPUT, ignore_errors=True)\n",
    "    \n",
    "os.makedirs(DATA_OUTPUT, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tuple_types = {}\n",
    "\n",
    "def flatten(item, verbose=False):\n",
    "    #print(f'Flattening: {item}')\n",
    "    #print(f'Shape: {item.shape}')\n",
    "    if item.dtype.kind in ['O', 'V'] and item.shape == (1,1): # prob. cell\n",
    "        if verbose:\n",
    "            print(\"Object\")\n",
    "        return flatten(item[0,0], verbose)\n",
    "    elif item.dtype.kind == 'V' and item.shape == tuple(): # prob structure\n",
    "        if verbose:\n",
    "            print(\"Void\")\n",
    "        if item.dtype.names not in named_tuple_types:\n",
    "            named_tuple_types[item.dtype.names] = collections.namedtuple('Structure', item.dtype.names)\n",
    "        conv = [flatten(x, verbose) for x in item]\n",
    "        assert len(conv) == len(item.dtype.names)\n",
    "        return named_tuple_types[item.dtype.names](*conv)\n",
    "    else :\n",
    "        if item.shape == (1,1):\n",
    "            return item[0,0]\n",
    "        elif item.shape == (1,):\n",
    "            return item[0]\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Other - ?')\n",
    "            return item\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatFileRun:\n",
    "    def __init__(self, mat_file_dataset, index):\n",
    "        self.glob = mat_file_dataset\n",
    "        self.y_evals = flatten(mat_file_dataset.y_evals[index, 0])\n",
    "        self.cmaes_out = flatten(mat_file_dataset.cmaes_out[0, index])\n",
    "        \n",
    "    @staticmethod\n",
    "    def keep_array(st):\n",
    "        if isinstance(st, (float, int)):\n",
    "            return np.array([st])\n",
    "        elif isinstance(st, np.ndarray) and len(st.shape) == 2 and st.shape[0] == 1:\n",
    "            return st[0,:]\n",
    "        elif isinstance(st, np.ndarray) and len(st.shape) == 2 and st.shape[1] == 1:\n",
    "            return st[:,0]\n",
    "        return st\n",
    "        \n",
    "    def save(self, path):\n",
    "        np.savez(path\n",
    "            , dimensions = self.glob.bbParams.dimensions # #of dim\n",
    "            , function_id = self.glob.bbParams.functions # function evaled\n",
    "            , restarts = self.glob.cmaesParams.Restarts  # restarts (maximum?)\n",
    "            , exp_id = self.glob.exp_id # name of experiment\n",
    "                 \n",
    "            , surrogate_param_set_size_max = self.glob.surrogateParams.modelOpts.trainsetSizeMax\n",
    "            , surrogate_param_range = self.glob.surrogateParams.modelOpts.trainRange\n",
    "            , surrogate_param_type = self.glob.surrogateParams.modelOpts.trainsetType\n",
    "            , surrogate_data_means = self.cmaes_out.means\n",
    "            , surrogate_data_sigmas = self.cmaes_out.sigmas\n",
    "            , surrogate_data_bds = np.stack(self.cmaes_out.BDs[0,:], axis=0)\n",
    "                 \n",
    "            , points = self.cmaes_out.arxvalids.T # points\n",
    "            , fvalues = self.keep_array(self.cmaes_out.fvalues) # baseline\n",
    "            , orig_evaled = self.keep_array(self.cmaes_out.origEvaled.astype(bool)) # fvalues is orig?\n",
    "            , gen_split = self.keep_array((self.cmaes_out.generationStarts - 1)) # gen \n",
    "            , iruns = self.keep_array(self.cmaes_out.iruns) # ??\n",
    "            , evals = self.cmaes_out.evals # evaluations of o. fitness function ?\n",
    "            , coco = self.keep_array(self.cmaes_out.fvaluesOrig) # !!! proc je to jinak??\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "class MatFileDataset:\n",
    "    '''\n",
    "        bbParams          -\n",
    "        cmaesParams       -\n",
    "        cmaes_out         - (run, 1)\n",
    "        exp_id            - str\n",
    "        exp_results       -\n",
    "        exp_settings      -\n",
    "        surrogateParams   - \n",
    "        y_evals           - (1, run)\n",
    "    '''\n",
    "    def __init__(self, data_path):\n",
    "        data_file = loadmat(data_path\n",
    "            , verify_compressed_data_integrity=True\n",
    "            , mat_dtype=False\n",
    "            , struct_as_record=True\n",
    "            )\n",
    "        \n",
    "        self._options_top_level = ['bbParams', 'cmaesParams', 'cmaes_out', 'exp_id', 'exp_results', 'exp_settings', 'surrogateParams', 'y_evals']\n",
    "        \n",
    "        self.__dict__.update(\n",
    "            {name: value for name, value in data_file.items() if not name.startswith('__')}\n",
    "        )\n",
    "        \n",
    "        self.bbParams = flatten(self.bbParams)\n",
    "        self.cmaesParams = flatten(self.cmaesParams)\n",
    "        #self.cmaes_out = _\n",
    "        self.exp_id = flatten(self.exp_id)\n",
    "        self.exp_results = flatten(self.exp_results)\n",
    "        self.exp_settings = flatten(self.exp_settings)\n",
    "        self.surrogateParams = flatten(self.surrogateParams)\n",
    "        #self.y_evals = _\n",
    "        \n",
    "    def consistency_check(self):\n",
    "        for i in self._options_top_level:\n",
    "            assert hasattr(self, i)\n",
    "            \n",
    "        assert isinstance(self.exp_id, str)\n",
    "            \n",
    "        #assert len(self.cmaes_out) == len(self.bbParams.instances) == len(self.y_evals)\n",
    "        \n",
    "    @staticmethod\n",
    "    def safe_cell_removal(array):\n",
    "        assert len(array) == 1\n",
    "        return array[0,0]\n",
    "        \n",
    "    @staticmethod\n",
    "    def convert_dtype_array_to_dictionary(array):\n",
    "        assert array.shape == tuple()\n",
    "        return {name: value for name, value in zip(array.dtype.names, array)}\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        iterator = [MatFileRun(self, i) for i in range(len(self.y_evals))]\n",
    "        return iter(iterator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # pouze pro testovani\n",
    "    \n",
    "    mf = MatFileDataset(DATA_PATH + \"exp_doubleEC_28_log_nonadapt_results_1_2D_3.mat\")\n",
    "    mf.cmaes_out[0,1][0,0][0,0]\n",
    "    \n",
    "    for run in mf:\n",
    "        pass\n",
    "\n",
    "    np.stack(run.cmaes_out.BDs[0,:], axis=0).shape\n",
    "    #run.cmaes_out.sigmas.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1056/1056 [04:01<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "mat_files = os.listdir(DATA_PATH)\n",
    "mat_files = filter(lambda x: x.endswith('.mat'), mat_files)\n",
    "mat_files = filter(lambda x: x.startswith('exp_doubleEC_28_log_nonadapt'), mat_files)\n",
    "mat_files = list(mat_files)\n",
    "\n",
    "for filename in tqdm.tqdm(mat_files):\n",
    "    strip_filename = filename[:-4]\n",
    "    data_path = DATA_PATH + filename\n",
    "    \n",
    "    mfd = MatFileDataset(data_path)\n",
    "    for runid, run in enumerate(mfd, start=0):\n",
    "        run.save(DATA_OUTPUT + strip_filename + f\"_{runid}.npz\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "def numpy_match(a,b):\n",
    "    #print(f\"{a.shape} vs {b.shape}\")\n",
    "    try:\n",
    "        #return (np.all(np.equal(a,b)), 'ok')\n",
    "        if a.dtype.kind == 'b':\n",
    "            return (np.all(np.equal(a,b)), 'ok')\n",
    "        else:\n",
    "            diff = np.mean(np.abs(a-b)) < 10e-6\n",
    "            #alll = np.all(diff)\n",
    "            #if not alll:\n",
    "            #    print(a[~diff] - b[~diff])\n",
    "            \n",
    "            return (diff, 'ok')\n",
    "    except Exception as e:\n",
    "        return (False, str(e))\n",
    "\n",
    "\n",
    "\n",
    "for run_name in os.listdir('../../npz-data'):\n",
    "    print(run)\n",
    "    a = np.load('../../npz-data/' + run_name)\n",
    "    b = np.load(DATA_OUTPUT +  run_name)\n",
    "    \n",
    "    exc1 = exc2 =  '<neni>'\n",
    "    \n",
    "    for key, val in a.items():\n",
    "        (r, exc1) = numpy_match(val, b[key])\n",
    "        if not r:\n",
    "            (r, exc2) = numpy_match(val, b[key][1:])\n",
    "        \n",
    "        if not r:\n",
    "            print(f\"{run_name} {key} {r}\\n\\t{exc1}\\n\\t{exc2}\")\n",
    "   ''' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
