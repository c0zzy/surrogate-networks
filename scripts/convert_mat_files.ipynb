{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataset_duplicits_toolkit.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import collections\n",
    "\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import import_ipynb\n",
    "from dataset_duplicits_toolkit import *\n",
    "\n",
    "\n",
    "DATA_PATH = '../../exp_doubleEC_28_log_nonadapt/'\n",
    "DATA_OUTPUT = '../../npz-data/'\n",
    "\n",
    "if False:\n",
    "    shutil.rmtree(DATA_OUTPUT, ignore_errors=True)\n",
    "    \n",
    "os.makedirs(DATA_OUTPUT, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tuple_types = {}\n",
    "\n",
    "def flatten(item, verbose=False):\n",
    "    #print(f'Flattening: {item}')\n",
    "    #print(f'Shape: {item.shape}')\n",
    "    if item.dtype.kind in ['O', 'V'] and item.shape == (1,1): # prob. cell\n",
    "        if verbose:\n",
    "            print(\"Object\")\n",
    "        return flatten(item[0,0], verbose)\n",
    "    elif item.dtype.kind == 'V' and item.shape == tuple(): # prob structure\n",
    "        if verbose:\n",
    "            print(\"Void\")\n",
    "        if item.dtype.names not in named_tuple_types:\n",
    "            named_tuple_types[item.dtype.names] = collections.namedtuple('Structure', item.dtype.names)\n",
    "        conv = [flatten(x, verbose) for x in item]\n",
    "        assert len(conv) == len(item.dtype.names)\n",
    "        return named_tuple_types[item.dtype.names](*conv)\n",
    "    else :\n",
    "        if item.shape == (1,1):\n",
    "            return item[0,0]\n",
    "        elif item.shape == (1,):\n",
    "            return item[0]\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Other - ?')\n",
    "            return item\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatFileRun:\n",
    "    def __init__(self, mat_file_dataset, index):\n",
    "        self.glob = mat_file_dataset\n",
    "        self.index = index\n",
    "        self.y_evals = flatten(mat_file_dataset.y_evals[index, 0])\n",
    "        self.cmaes_out = flatten(mat_file_dataset.cmaes_out[0, index])\n",
    "        \n",
    "    @staticmethod\n",
    "    def keep_array(st):\n",
    "        if isinstance(st, (float, int, np.int64, np.int32, np.int16, np.bool)):\n",
    "            return np.array([st])\n",
    "        elif isinstance(st, np.ndarray) and len(st.shape) == 2 and st.shape[0] == 1:\n",
    "            return st[0,:]\n",
    "        elif isinstance(st, np.ndarray) and len(st.shape) == 2 and st.shape[1] == 1:\n",
    "            return st[:,0]\n",
    "        return st\n",
    "    \n",
    "    def get_filtered_content(self):\n",
    "        points = self.cmaes_out.arxvalids.T # points\n",
    "        fvalues = self.keep_array(self.cmaes_out.fvalues) # baseline\n",
    "        orig_evaled = self.keep_array(self.cmaes_out.origEvaled.astype(bool)) # fvalues is orig?\n",
    "        gen_split = self.keep_array((self.cmaes_out.generationStarts - 1)) # gen \n",
    "        fvalues_orig = self.keep_array(self.cmaes_out.fvaluesOrig) # !!! proc je to jinak??\n",
    "        \n",
    "        mask = duplicit_mask_with_hot_elements(points, orig_evaled)\n",
    "        \n",
    "        points = points[mask, ...]\n",
    "        fvalues = fvalues[mask]\n",
    "        orig_evaled = orig_evaled[mask]\n",
    "        fvalues_orig = fvalues_orig[mask]\n",
    "        gen_split = move_indices_given_boolean_mask(mask, gen_split)\n",
    "        \n",
    "        return {'points':points \n",
    "            , 'fvalues':fvalues\n",
    "            , 'orig_evaled': orig_evaled\n",
    "            , 'fvalues_orig': fvalues_orig\n",
    "            , 'gen_split': gen_split\n",
    "        }\n",
    "        \n",
    "    def save(self, path):\n",
    "        np.savez(path\n",
    "            , dimensions = self.glob.bbParams.dimensions # #of dim\n",
    "            , function_id = self.glob.bbParams.functions # function evaled\n",
    "            , restarts = self.glob.cmaesParams.Restarts  # restarts (maximum?)\n",
    "            , exp_id = self.glob.exp_id # name of experiment\n",
    "                 \n",
    "            , surrogate_param_set_size_max = self.glob.surrogateParams.modelOpts.trainsetSizeMax\n",
    "            , surrogate_param_range = self.glob.surrogateParams.modelOpts.trainRange\n",
    "            , surrogate_param_type = self.glob.surrogateParams.modelOpts.trainsetType\n",
    "            , surrogate_data_means = self.cmaes_out.means\n",
    "            , surrogate_data_sigmas = self.cmaes_out.sigmas\n",
    "            , surrogate_data_bds = np.stack(self.cmaes_out.BDs[0,:], axis=0)\n",
    "                 \n",
    "            #, points = self.cmaes_out.arxvalids.T # points\n",
    "            #, fvalues = self.keep_array(self.cmaes_out.fvalues) # baseline\n",
    "            #, orig_evaled = self.keep_array(self.cmaes_out.origEvaled.astype(bool)) # fvalues is orig?\n",
    "            #, gen_split = self.keep_array((self.cmaes_out.generationStarts - 1)) # gen \n",
    "            #, coco = self.keep_array(self.cmaes_out.fvaluesOrig) # !!! proc je to jinak??\n",
    "                 \n",
    "            , iruns = self.keep_array(self.cmaes_out.iruns) # ??\n",
    "            , evals = self.cmaes_out.evals # evaluations of o. fitness function ?\n",
    "            , **self.get_filtered_content()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatFileDataset:\n",
    "    '''\n",
    "        bbParams          -\n",
    "        cmaesParams       -\n",
    "        cmaes_out         - (run, 1)\n",
    "        exp_id            - str\n",
    "        exp_results       -\n",
    "        exp_settings      -\n",
    "        surrogateParams   - \n",
    "        y_evals           - (1, run)\n",
    "    '''\n",
    "    def __init__(self, data_path):\n",
    "        data_file = loadmat(data_path\n",
    "            , verify_compressed_data_integrity=True\n",
    "            , mat_dtype=False\n",
    "            , struct_as_record=True\n",
    "            )\n",
    "        \n",
    "        self._options_top_level = ['bbParams', 'cmaesParams', 'cmaes_out', 'exp_id', 'exp_results', 'exp_settings', 'surrogateParams', 'y_evals']\n",
    "        self._data_path = data_path\n",
    "        \n",
    "        self.__dict__.update(\n",
    "            {name: value for name, value in data_file.items() if not name.startswith('__')}\n",
    "        )\n",
    "        \n",
    "        self.bbParams = flatten(self.bbParams)\n",
    "        self.cmaesParams = flatten(self.cmaesParams)\n",
    "        #self.cmaes_out = _\n",
    "        self.exp_id = flatten(self.exp_id)\n",
    "        self.exp_results = flatten(self.exp_results)\n",
    "        self.exp_settings = flatten(self.exp_settings)\n",
    "        self.surrogateParams = flatten(self.surrogateParams)\n",
    "        #self.y_evals = _\n",
    "        \n",
    "    def consistency_check(self):\n",
    "        for i in self._options_top_level:\n",
    "            assert hasattr(self, i)\n",
    "            \n",
    "        assert isinstance(self.exp_id, str)\n",
    "            \n",
    "        #assert len(self.cmaes_out) == len(self.bbParams.instances) == len(self.y_evals)\n",
    "        \n",
    "    @staticmethod\n",
    "    def safe_cell_removal(array):\n",
    "        assert len(array) == 1\n",
    "        return array[0,0]\n",
    "        \n",
    "    @staticmethod\n",
    "    def convert_dtype_array_to_dictionary(array):\n",
    "        assert array.shape == tuple()\n",
    "        return {name: value for name, value in zip(array.dtype.names, array)}\n",
    "        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        iterator = [MatFileRun(self, i) for i in range(len(self.y_evals))]\n",
    "        return iter(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # pouze pro testovani\n",
    "    \n",
    "    #mf = MatFileDataset(DATA_PATH + \"exp_doubleEC_28_log_nonadapt_results_1_2D_3.mat\")\n",
    "    mf = MatFileDataset(DATA_PATH + 'exp_doubleEC_28_log_nonadapt_results_5_2D_37.mat')\n",
    "    for run in mf:\n",
    "        pass\n",
    "    \n",
    "    print(run.get_filtered_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    from multiprocessing import Pool\n",
    "    N_CORES = os.cpu_count() * 2\n",
    "else:\n",
    "    N_CORES = 1\n",
    "\n",
    "mat_files = os.listdir(DATA_PATH)\n",
    "mat_files = filter(lambda x: x.endswith('.mat'), mat_files)\n",
    "mat_files = filter(lambda x: x.startswith('exp_doubleEC_28_log_nonadapt'), mat_files)\n",
    "mat_files = list(mat_files)\n",
    "\n",
    "def paralel_function(filename):\n",
    "    strip_filename = filename[:-4]\n",
    "    data_path = DATA_PATH + filename\n",
    "    \n",
    "    mfd = MatFileDataset(data_path)\n",
    "    for runid, run in enumerate(mfd, start=0):\n",
    "        run.save(DATA_OUTPUT + strip_filename + f\"_{runid}.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1056/1056 [07:27<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if N_CORES <= 1:\n",
    "    for filename in tqdm.tqdm(mat_files):\n",
    "        paralel_function(filename)\n",
    "else:\n",
    "    import random\n",
    "    random.shuffle(mat_files)\n",
    "    with Pool(N_CORES) as p:\n",
    "        v = p.imap_unordered(paralel_function, mat_files)\n",
    "        list(tqdm.tqdm(v, total=len(mat_files)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
